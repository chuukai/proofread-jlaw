{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "publicanbunparse.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "14AQ4ot4YYY6uii3xkAFUAhxM3hHKU8gw",
      "authorship_tag": "ABX9TyPE6ug8uza/04X5yNguhfaU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LocdOynSwhfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc38bc8e-d287-4b1b-f396-72dfa72d4d3a"
      },
      "source": [
        "# 形態素分析ライブラリーMeCab と 辞書(mecab-ipadic-NEologd)のインストール \n",
        "!apt-get -q -y install sudo file mecab libmecab-dev mecab-ipadic-utf8 git curl python-mecab > /dev/null\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null \n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n > /dev/null 2>&1\n",
        "!pip install mecab-python3 > /dev/null\n",
        " \n",
        "# シンボリックリンクによるエラー回避\n",
        "!ln -s /etc/mecabrc /usr/local/etc/mecabrc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mecab-ipadic-neologd'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 75 (delta 5), reused 54 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (75/75), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUIz2w5_nme8"
      },
      "source": [
        "import os\n",
        "import MeCab\n",
        "import re\n",
        "import subprocess\n",
        "import sys\n",
        "path = \"-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd -b 819200\"\n",
        "m = MeCab.Tagger(path)\n",
        "noun_list = ''\n",
        "pos_list = ''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def ommit(linestr):\n",
        "  line = linestr.rstrip('\\n')\n",
        "  t_lists = line.split('\\t')\n",
        "  term = t_lists[0] + ' '\n",
        "  if t_lists[0] == 'EOS' or t_lists[0] == '' or t_lists[0] == 'と' or t_lists[0] == 'の':\n",
        "    term = ''\n",
        "    return term\n",
        "  for hinsi in ['記号', '助詞,連体化', '助詞,副詞化', '助詞,係助詞', '助詞,接続助詞', '助詞,並立助詞', '助詞,副助詞／並立助詞／終助詞', '助詞,格助詞,引用', '助詞,格助詞,一般,*,*,*,へ,ヘ,エ', '助詞,格助詞,一般,*,*,*,に,ニ,ニ', '助詞,格助詞,一般,*,*,*,を,ヲ,ヲ', '助詞,格助詞,一般,*,*,*,で,デ,デ', '助詞,格助詞,一般,*,*,*,が,ガ,ガ', '助詞,格助詞,一般,*,*,*,から,カラ,カラ', '助詞,副助詞,*,*,*,*,まで,マデ,マデ', '連体詞', '接頭詞,名詞接続', '特殊', '形容詞,自立,*,*,形容詞・アウオ段,基本形,ない,ナイ,ナイ', '接頭詞,数接続', '名詞,数', '名詞,接尾', '名詞,非自立,副詞可能', '名詞,非自立,助動詞語幹', '名詞,接尾,助数詞', '名詞,代名詞', '助動詞', '名詞,非自立,一般', '動詞,非自立', '動詞,自立,*,*,サ変・スル', '動詞,接尾', '動詞,自立,*,*,一段,基本形,できる,デキル,デキル', '動詞,自立,*,*,五段・ラ行,基本形,係る,カカル,カカル', '助詞,格助詞,連語,*,*,*,に' ]:\n",
        "    if t_lists[1].find(hinsi) > -1:\n",
        "      term = ''\n",
        "      return term\n",
        "  for stopword in ['ヶ所', 'ヵ所', 'カ所', '箇所', 'ヶ月', 'ヵ月', 'カ月', '箇月', '十', '百', '千', '万', '億', '兆', 'もの', '明治', '大正', '昭和', '平成', '令和']:\n",
        "    if t_lists[0].find(stopword) > -1:\n",
        "      term = ''\n",
        "      return term\n",
        "  return linestr\n",
        "\n",
        "for bunrui in range(1,51):\n",
        "  lssentence = \" \".join(['ls','/content/drive/My\\ Drive/Colab\\ Notebooks/houreibunrui20210510/%02d/*.nml' % bunrui])\n",
        "  output = subprocess.getoutput(lssentence)\n",
        "  tolists = output.split('\\n')\n",
        "  for tolist in tolists:\n",
        "    print(tolist)\n",
        "    text_data = open(tolist, \"rb\").read()\n",
        "    decoded_text = text_data.decode('utf-8')\n",
        "    text = re.sub('\\n\\n', '\\n', decoded_text)\n",
        "    with open(tolist[:125] + '.poslist', 'a') as f:\n",
        "      parses = m.parse(text)\n",
        "      tolistformecab = re.sub(\" \", \"\\ \", tolist)\n",
        "      mecabsentence = \" \".join(['cat', tolistformecab, '|', 'mecab', path, '>', 'temp.poslist'])\n",
        "      subprocess.getoutput(mecabsentence)\n",
        "      with open('temp.poslist', encoding='utf8') as ftemp:\n",
        "        for linestr in ftemp:\n",
        "          f.write(ommit(linestr))\n",
        "      !rm temp.poslist\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_m3R8Dl8c8j"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "import subprocess\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "f=open('/content/drive/My Drive/Colab Notebooks/houreibunrui20210510/bunruiwall-sort-uniq-poslist2.csv')\n",
        "lines=f.readlines()\n",
        "f.close()\n",
        "bfs = []\n",
        "sums= []\n",
        "nums = []\n",
        "mods = []\n",
        "bunrui = 0\n",
        "bunruii = 1\n",
        "for line in lines:\n",
        "  bunrui = int(line[0:2])\n",
        "  fn = line[3:64]\n",
        "  size = int(line[65:].replace(\"\\n\", \"\"))\n",
        "  bfs.append((bunrui, fn, size))\n",
        "#bfsは(分類、分かち書き後のファイルネーム、サイズ)のリスト\n",
        "sums = [0, 0]\n",
        "nums = [0]\n",
        "mods = [0]\n",
        "bunruilens = [0]\n",
        "bunruilen = 0\n",
        "for bfsi in bfs:\n",
        "  if bfsi[0]  == bunruii:\n",
        "#bfsiは(分類、分かち書き後のファイルネーム、サイズ)のタプル\n",
        "    sums[bunruii] = sums[bunruii] + bfsi[2]\n",
        "    bunruilen += 1\n",
        "  elif sums[bunruii]//1690000  == 0:\n",
        "    nums.append(1)\n",
        "    mods.append(0)\n",
        "    sums.append(bfsi[2])\n",
        "    bunruilens.append(bunruilen)\n",
        "    print(bunruii, 1, 0, bunruilen)\n",
        "    bunruilen = 1\n",
        "    bunruii = bfsi[0]\n",
        "  else:\n",
        "    nums.append(sums[bunruii]//1690000 + 1)\n",
        "    mods.append(((sums[bunruii] % -1690000)//(nums[bunruii] - 1)) * -1)\n",
        "    sums.append(bfsi[2])\n",
        "    bunruilens.append(bunruilen)\n",
        "    print(bunruii, sums[bunruii], sums[bunruii]//1690000 + 1, ((sums[bunruii] % -1690000)//(nums[bunruii] - 1)) * -1, bunruilen)\n",
        "    bunruilen = 1\n",
        "    bunruii = bfsi[0]\n",
        "if sums[bunruii]//1690000  == 0:\n",
        "  nums.append(1)\n",
        "  mods.append(0)\n",
        "  bunruilens.append(bunruilen)\n",
        "  print(bunruii, 1, 0)\n",
        "else:\n",
        "  nums.append(sums[bunruii]//1690000 + 1)\n",
        "  mods.append(((sums[bunruii] % -1690000)//(nums[bunruii] - 1)) * -1)\n",
        "  bunruilens.append(bunruilen)\n",
        "  print(bunruii, sums[bunruii]//1690000 + 1, ((sums[bunruii] % -1690000)//(nums[bunruii] - 1)) * -1, bunruilen)\n",
        "print(len(sums), len(nums), len(mods), len(bunruilens))\n",
        "print(bunruilens)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI7kBF7JJVYU"
      },
      "source": [
        "wakati = ['']\n",
        "wakatilist = []\n",
        "wakatilistbw = []\n",
        "numw = 0\n",
        "sumfw = 0\n",
        "sumbw = 0\n",
        "t = 0\n",
        "def writeallwakati(bunruii, numw, wakatilist):\n",
        "  from pprint import pprint\n",
        "  import pickle\n",
        "  import json\n",
        "  texts = []\n",
        "  text = []\n",
        "  fn = '%02d-%02dw.allposlist.pkl' % (bunruii, numw)\n",
        "  for tolist in wakatilist:\n",
        "    if not tolist == '':\n",
        "      with open('/content/drive/My Drive/Colab Notebooks/houreibunrui20210510/%02d/' % bunruii + tolist[0], \"rb\") as fr:\n",
        "        text = [row.decode('utf-8').split(\",\")[0].replace('\\t', ',') for row in fr]\n",
        "        texts += set(text)\n",
        "  results = {}\n",
        "  for textline in sorted(set(texts)):\n",
        "    word, pos = textline.split(\",\")\n",
        "    results.setdefault(word, []).append(pos)\n",
        "  open(fn, 'wb').write(pickle.dumps(results))\n",
        "\n",
        "for bunruii in range(1, 51):\n",
        "  start = sum(bunruilens[0:bunruii])\n",
        "  end = sum(bunruilens[0:bunruii + 1]) - 1\n",
        "  print(bunruii, start, end)\n",
        "  for t1, bfsi in enumerate(bfs[start:end + 1]):\n",
        "    sumfw = sumfw + int(bfsi[2])\n",
        "    if sumfw > 1590000:\n",
        "      print('reversed', bunruii, sumfw)\n",
        "      wakati.append((bunruii, numw, wakatilist))\n",
        "      writeallwakati(bunruii, numw, wakatilist)\n",
        "      wakatilist = []\n",
        "      wakatilistbw = []\n",
        "      numw += 1\n",
        "      sumfw = 0\n",
        "      for t2, bfsbw in enumerate(reversed(bfs[start:start + t1])):\n",
        "        sumbw = sumbw + int(bfsbw[2])\n",
        "        print(sumbw, int(mods[bunruii])/(int(nums[bunruii]) - 1))\n",
        "        if sumbw > int(mods[bunruii])/(int(nums[bunruii]) - 1):\n",
        "          sumfw = sumbw - int(bfsbw[2]) + int(bfsi[2]) \n",
        "          print('sumfw is %d' % sumfw)\n",
        "          wakatilist = wakatilistbw[:]\n",
        "          wakatilistbw = []\n",
        "          sumbw = 0\n",
        "          break\n",
        "        wakatilistbw.append((bfsbw[1][:53] + \".poslist\", bfsbw[2]))\n",
        "        print(t2, sumbw)\n",
        "      else:\n",
        "        sumfw = sumbw + int(bfsi[2]) \n",
        "        print('sumbw is %d' % sumbw)\n",
        "        wakatilist = wakatilistbw[:]\n",
        "        wakatilistbw = []\n",
        "        sumbw = 0\n",
        "    wakatilist.append((bfsi[1][:53] + \".poslist\", bfsi[2]))\n",
        "    print(t1, sumfw)\n",
        "  wakati.append((bunruii, numw, wakatilist))\n",
        "  writeallwakati(bunruii, numw, wakatilist)\n",
        "  wakatilist = []\n",
        "  wakatilistbw = []\n",
        "  sumfw = 0\n",
        "  numw = 0\n",
        "  sumbw = 0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twVUdhiebebX"
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Activation, concatenate\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "from keras.layers.core import Dropout, Reshape, Permute, RepeatVector, Flatten, Lambda\n",
        "from keras.layers.normalization import BatchNormalization as BN\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.optimizers import RMSprop, Adam, Adagrad, Nadam, SGD, Adadelta, Adamax\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import glob\n",
        "from time import gmtime, strftime\n",
        "import copy\n",
        "import pickle\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "def pred(wakatialllists, fnb, fnp, bunrui):\n",
        "  rng = 5\n",
        "  writetexts = []\n",
        "  poslistdic = {}\n",
        "  print(fnb)\n",
        "  with open('/content/drive/My Drive/Colab Notebooks/houreibunrui20210510/' + bunrui + '/' + fnp, \"rb\") as fr:\n",
        "    text = [row.decode('utf-8').split(\",\")[0].replace('\\t', ',') for row in fr]\n",
        "  for textline in sorted(set(text)):\n",
        "    word, pos = textline.split(\",\")\n",
        "    poslistdic.setdefault(word, []).append(pos)\n",
        "\n",
        "\n",
        "  for wakatialllis in wakatialllists:\n",
        "    wakatialllist = wakatialllis.strip()\n",
        "    print(\"start to loading term_vec and poslist\")\n",
        "    ansindx = []\n",
        "    term_vec = []\n",
        "    term_vec_lists = pickle.loads(open('/content/' + wakatialllist + '.term_vec.pkl', 'rb').read())\n",
        "    allposlistdic = pickle.loads(open('/content/' + wakatialllist + '.allposlist.pkl', 'rb').read())\n",
        "    text = open('/content/drive/My Drive/Colab Notebooks/houreibunrui20210510/' + wakatialllist[0:2] + '/' + fnb, 'r').read().replace('\\n', ' ').split()\n",
        "    if len(text) < 11:\n",
        "      break\n",
        "    picking_up = []\n",
        "    for term_vec_list in term_vec_lists:\n",
        "      term_vec.append([term_vec_list[0], term_vec_list[2]])\n",
        "      ansindx.append(term_vec_list[0])\n",
        "    print(len(term_vec))\n",
        "    term_vec_lists = []\n",
        "    for i in range(rng, len(text) - rng, 1):\n",
        "      try:\n",
        "        head = list(map(lambda x:term_vec[ansindx.index(x)][1], text[i-rng:i] )) \n",
        "        tail = list(map(lambda x:term_vec[ansindx.index(x)][1], text[i+1:i+rng] )) \n",
        "      except ValueError as e:\n",
        "        continue\n",
        "      head.extend(tail)\n",
        "      x = np.array(head)\n",
        "      y = text[i]\n",
        "      picking_up.append( (x, y, text[i-rng:i+rng]) )\n",
        "    print(len(picking_up))\n",
        "    answers   = []\n",
        "    texts     = []\n",
        "    writetext = []\n",
        "    sentences = []\n",
        "    for dbi, picked in enumerate(picking_up):\n",
        "      x, y,  pure_text = picked\n",
        "      sentences.append(x)\n",
        "      answers.append(y)\n",
        "      texts.append(pure_text)\n",
        "    if len(sentences) == 0:\n",
        "      break\n",
        "    X = np.zeros((len(sentences), len(sentences[0]), 128), dtype=np.float64)\n",
        "    for i, sentence in enumerate(sentences):\n",
        "      if i%10000 == 0:\n",
        "        print(\"building training vector... iter %d\"%i)\n",
        "      for t, vec in enumerate(sentence):\n",
        "        X[i, t, :] = vec\n",
        "\n",
        "\n",
        "    model_type = './models' + wakatialllist + '/snapshot.000000030.model'\n",
        "    print(\"model type is %s\"%model_type)\n",
        "    model  = load_model(model_type)\n",
        "    results = model.predict(X)\n",
        "    itext = 0\n",
        "    j = 0\n",
        "    for sent, xtext, result in zip(sentences, texts, results):\n",
        "      itext = itext + 1\n",
        "      while not text[itext] == xtext[5]:\n",
        "        writetext.append(text[itext] + ':,')\n",
        "        itext = itext + 1\n",
        "      wtext = xtext[5] + ':'\n",
        "      for i,f in sorted([(i,f) for i,f in enumerate(result.tolist())], key=lambda x:x[1]*-1):\n",
        "        if f < 0.99:\n",
        "          writetext.append(wtext)\n",
        "          break\n",
        "        if xtext[5] != ansindx[i] and set(poslistdic[xtext[5]]) & set(allposlistdic[ansindx[i]]):\n",
        "          wtext = wtext + ansindx[i] + ';' + str(f) + ','\n",
        "        j += 1\n",
        "        if j % 5 == 0:\n",
        "          writetext.append(wtext)\n",
        "          break\n",
        "    writetexts.append(writetext)\n",
        "  return writetexts\n",
        "dictwakatiall = {}\n",
        "%cd /content/drive/My\\ Drive/Colab\\ Notebooks/houreibunrui20210510/01-50wakatiall/\n",
        "lswakatiall = \" \".join(['ls','*.wwakatiall'])\n",
        "output = subprocess.getoutput(lswakatiall)\n",
        "%cd /content/\n",
        "for fni in output.split('\\n'):\n",
        "  if fni[0:2] in dictwakatiall:\n",
        "    dictwakatiall[fni[0:2]].append(fni.strip())\n",
        "  else:\n",
        "    dictwakatiall.update({fni[0:2] : [fni.strip()]})\n",
        "f=open('/content/drive/My Drive/Colab Notebooks/houreibunrui20210510/bunruiwall-sort-uniq2.csv')\n",
        "lines=f.readlines()\n",
        "f.close()\n",
        "writetext = []\n",
        "writetexts = []\n",
        "outputs = []\n",
        "for line in lines:\n",
        "  wakatialllists = dictwakatiall[line[0:2]]\n",
        "  fnb = line[3:64]\n",
        "  fnp = line[3:56] + '.poslist'\n",
        "  bunrui = line[0:2]\n",
        "  writetexts = pred(wakatialllists, fnb, fnp, bunrui)\n",
        "  with open('pred' + fnb + '.txt', 'a') as fwt:\n",
        "    for ls in zip(*writetexts):\n",
        "      fwt.write('|'.join(ls) + \"\\n\")\n",
        "!zip /content/drive/My\\ Drive/Colab\\ Notebooks/houreibunrui20210510/wwakati.zip *.txt"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}